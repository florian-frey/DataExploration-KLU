{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Training Data\n",
    "Data source: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
    "\n",
    "- target:   The polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "- ids:      The id of the tweet\n",
    "\n",
    "- date:     The date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "- flag:     The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "- user:     The user that tweeted\n",
    "\n",
    "- text:     The text of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile(\"training_data.zip\", \"r\")\n",
    "data = pd.read_csv(archive.open(\"training.1600000.processed.noemoticon.csv\"), header=None, encoding_errors=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no neutral labelled tweets.\n",
    "So we change the labels to binary form.\n",
    "(0 = negative\n",
    "1 = positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[0]==4, 0] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model training we only need the label and text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([1,2,3,4], axis=1)\n",
    "data.columns = [\"label\",\"raw_text\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning everything into lowercase characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = [entry.lower() for entry in data[\"raw_text\"]]\n",
    "# data.head()\n",
    "# data[\"text\"] = data[\"raw_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords and Links and User-Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "# we think 'no' and 'not' might be important words for the sentiment and don't want them to be removed\n",
    "stop.remove(\"no\")\n",
    "stop.remove(\"not\")\n",
    "\n",
    "# data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(\"http[s]?://\\S+\", \"\", x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(\"@\\S+\", \"\", x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(\"-|\\.|,|'|\\?|\\!\", \"\", x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word-Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# sstemmer = SnowballStemmer(\"english\")\n",
    "# pstemmer = PorterStemmer()\n",
    "\n",
    "# data['text'] = data['text'].apply(lambda x: ' '.join([sstemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process takes a few minutes. So you only need to do it once, save it to a csv-file and read that file\n",
    "### comment these lines after running once:\n",
    "# data[\"text\"] = [word_tokenize(entry) for entry in data[\"text\"]]\n",
    "# data.to_csv('tokenized_data.csv', index=False)\n",
    "###\n",
    "\n",
    "data = pd.read_csv('tokenized_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our finished data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>['awww', 'thats', 'a', 'bummer', 'you', 'shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>['is', 'upset', 'that', 'he', 'cant', 'update'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>['i', 'dived', 'many', 'times', 'for', 'the', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['my', 'whole', 'body', 'feels', 'itchy', 'and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>['no', 'its', 'not', 'behaving', 'at', 'all', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           raw_text  \\\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1      0  is upset that he can't update his Facebook by ...   \n",
       "2      0  @Kenichan I dived many times for the ball. Man...   \n",
       "3      0    my whole body feels itchy and like its on fire    \n",
       "4      0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                                text  \n",
       "0  ['awww', 'thats', 'a', 'bummer', 'you', 'shoul...  \n",
       "1  ['is', 'upset', 'that', 'he', 'cant', 'update'...  \n",
       "2  ['i', 'dived', 'many', 'times', 'for', 'the', ...  \n",
       "3  ['my', 'whole', 'body', 'feels', 'itchy', 'and...  \n",
       "4  ['no', 'its', 'not', 'behaving', 'at', 'all', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(data[\"text\"], data[\"label\"],test_size=0.20, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "# we think 'no' and 'not' might be important words for the sentiment and don't want them to be removed\n",
    "stop.remove(\"no\")\n",
    "stop.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(analyzer=\"word\", strip_accents=\"unicode\", stop_words=stop, min_df=10)\n",
    "Data_Tfidf = Tfidf_vect.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_Tfidf = Tfidf_vect.transform(data[\"text\"])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 35016\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Features:\", len(Tfidf_vect.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.8331542 , 0.97276592, 0.87712479, 0.78345704, 0.78779507,\n",
       "        0.74288034, 0.81502581, 1.02199936, 0.75476074, 0.74301982]),\n",
       " 'score_time': array([0.0649817 , 0.07127166, 0.05353975, 0.05253625, 0.04892564,\n",
       "        0.04993916, 0.05719161, 0.08049512, 0.0522306 , 0.04152632]),\n",
       " 'test_score': array([0.76240625, 0.7641125 , 0.7528875 , 0.76394375, 0.76575625,\n",
       "        0.756375  , 0.76336875, 0.774675  , 0.7667    , 0.75955625])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_validate(naive_bayes.MultinomialNB(), Data_Tfidf, data[\"label\"], cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "NB = naive_bayes.MultinomialNB()\n",
    "NB.fit(Data_Tfidf, data[\"label\"])\n",
    "\n",
    "# predictions_NB = NB.predict(Test_X_Tfidf)\n",
    "# print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Classifier\n",
    "# SVM = svm.SVC(C=0.9, kernel='rbf', degree=3, gamma='auto', cache_size= 1000, max_iter=2500, decision_function_shape=\"ovo\", random_state=10)\n",
    "# SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_excel(\"api_responses\\data_20220615-111428.json.xlsx\")\n",
    "testdata = testdata[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I stayed up all night playing stardew valley. ...\n",
       "1     Stardew Valley 1.5 Random Bundles  E157 Enteri...\n",
       "2                   bacc at my stardew valley grind era\n",
       "3     It's 2am... I need to go to sleep... I've been...\n",
       "4         I started Stardew Valley for the first time 😅\n",
       "                            ...                        \n",
       "95    @hauntmallows POV: You're Clint from Stardew V...\n",
       "96    @Draconic_mer Awesome!!! Have you seen dangero...\n",
       "97    i wanna play stardew valley on stream again ju...\n",
       "98    @thepoggingman I still need to play stardew va...\n",
       "99    There's a stardew valley game trial on switch ...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = testdata\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 32559)\t0.3699750847461673\n",
      "  (0, 28847)\t0.3182368695627071\n",
      "  (0, 23193)\t0.248664455035521\n",
      "  (0, 20884)\t0.1825565584874412\n",
      "  (0, 14857)\t0.48829586301554434\n",
      "  (0, 11115)\t0.4654761767209046\n",
      "  (0, 10593)\t0.2959136441702954\n",
      "  (0, 6535)\t0.3521604996789864\n",
      "  (1, 34555)\t0.221162166512661\n",
      "  (1, 32559)\t0.34805875169901856\n",
      "  (1, 24576)\t0.2835148217445709\n",
      "  (1, 23160)\t0.38497687254888713\n",
      "  (1, 15022)\t0.36964242423237065\n",
      "  (1, 14857)\t0.4593705239843071\n",
      "  (1, 10278)\t0.379392179656457\n",
      "  (1, 6535)\t0.3312994549350945\n",
      "  (2, 32559)\t0.46074122896168623\n",
      "  (2, 13322)\t0.46213820581891196\n",
      "  (2, 10353)\t0.4958079199554629\n",
      "  (2, 2963)\t0.5729924128352741\n",
      "  (3, 32559)\t0.4143467096065845\n",
      "  (3, 29167)\t0.29515060694291984\n",
      "  (3, 27711)\t0.2226255197048213\n",
      "  (3, 20638)\t0.20995866457336002\n",
      "  (3, 14857)\t0.5468578628580049\n",
      "  :\t:\n",
      "  (96, 26695)\t0.23958176025290603\n",
      "  (96, 14857)\t0.4562891731384883\n",
      "  (96, 12257)\t0.2319486710033482\n",
      "  (96, 8041)\t0.4266022567024747\n",
      "  (96, 6535)\t0.32907717509260626\n",
      "  (96, 2810)\t0.199902869457339\n",
      "  (97, 32559)\t0.4333425057477043\n",
      "  (97, 29088)\t0.4062798477193116\n",
      "  (97, 26893)\t0.3747210562685423\n",
      "  (97, 24255)\t0.28579604964597144\n",
      "  (97, 23177)\t0.2798869983037776\n",
      "  (97, 19792)\t0.47408266659475656\n",
      "  (97, 17373)\t0.3492343045293881\n",
      "  (98, 32559)\t0.6392328353662485\n",
      "  (98, 28948)\t0.3111081859420547\n",
      "  (98, 23177)\t0.41286732119474295\n",
      "  (98, 20638)\t0.323913450627791\n",
      "  (98, 17923)\t0.46820265956244306\n",
      "  (99, 32559)\t0.47601673366765146\n",
      "  (99, 31448)\t0.49595476516840015\n",
      "  (99, 29751)\t0.4406095298763776\n",
      "  (99, 25594)\t0.2538833516809464\n",
      "  (99, 17495)\t0.3149486142887358\n",
      "  (99, 12386)\t0.3085766060691177\n",
      "  (99, 8175)\t0.27282095711468596\n"
     ]
    }
   ],
   "source": [
    "testdata = Tfidf_vect.transform(testdata)\n",
    "print(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_NB = NB.predict(testdata)\n",
    "predictions_NB = pd.Series(predictions_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     1\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(predictions_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I stayed up all night playing stardew valley. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stardew Valley 1.5 Random Bundles  E157 Enteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bacc at my stardew valley grind era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It's 2am... I need to go to sleep... I've been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I started Stardew Valley for the first time 😅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>@hauntmallows POV: You're Clint from Stardew V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>@Draconic_mer Awesome!!! Have you seen dangero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>i wanna play stardew valley on stream again ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>@thepoggingman I still need to play stardew va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>There's a stardew valley game trial on switch ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                               text\n",
       "0   0  I stayed up all night playing stardew valley. ...\n",
       "1   1  Stardew Valley 1.5 Random Bundles  E157 Enteri...\n",
       "2   0                bacc at my stardew valley grind era\n",
       "3   0  It's 2am... I need to go to sleep... I've been...\n",
       "4   1      I started Stardew Valley for the first time 😅\n",
       ".. ..                                                ...\n",
       "95  1  @hauntmallows POV: You're Clint from Stardew V...\n",
       "96  1  @Draconic_mer Awesome!!! Have you seen dangero...\n",
       "97  1  i wanna play stardew valley on stream again ju...\n",
       "98  1  @thepoggingman I still need to play stardew va...\n",
       "99  1  There's a stardew valley game trial on switch ...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.concat([predictions_NB, review], axis=1)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_excel(\"test.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69a1a1d853624da88fe3a3558871328a73b555428be3313eebd574666bb37328"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
